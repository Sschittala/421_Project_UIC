{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, mean_absolute_error, accuracy_score, f1_score\n",
        "import csv\n",
        "import os"
      ],
      "metadata": {
        "id": "uUVlT6OYYnbE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-3\n",
        "embed_dim = 128\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "dropout = 0.3\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k4YI29cgTjL",
        "outputId": "c5f952e3-ddd4-47c3-9918-ae34574b5b68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filepath):\n",
        "  return pd.read_csv(\n",
        "      filepath,\n",
        "      engine=\"python\",\n",
        "      sep = \",\",\n",
        "      escapechar='\\\\',\n",
        "      quotechar='\"',\n",
        "      quoting=csv.QUOTE_MINIMAL,\n",
        "      on_bad_lines='skip'\n",
        "  )\n",
        "col_emo = \"Emotion\"\n",
        "col_emo_pol = \"EmotionalPolarity\"\n",
        "col_emp = \"Empathy\"\n",
        "\n",
        "train_df = read_file(\"/content/trac2_CONVT_train.csv\")\n",
        "test_df = read_file(\"/content/trac2_CONVT_test.csv\")\n",
        "dev_df = read_file(\"/content/trac2_CONVT_dev.csv\")\n",
        "train_df = train_df.query(f\"{col_emo_pol} in [0, 1, 2]\").reset_index(drop=True)\n",
        "dev_df   = dev_df.query(f\"{col_emo_pol} in [0, 1, 2]\").reset_index(drop=True)\n",
        "\n",
        "len(train_df), len(dev_df), len(test_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVPr74rkgjU9",
        "outputId": "f033767c-e3eb-454e-80a8-2726f62ecab6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10940, 952, 2316)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "  return text.lower().split()\n",
        "pad_token = \"<pad>\"\n",
        "unk_token = \"<unk>\"\n",
        "def create_vocab(tokens):\n",
        "  vocab = [pad_token, unk_token] + sorted(tokens)\n",
        "  word2idx, idx2word = {},{}\n",
        "  for i, word in enumerate(vocab):\n",
        "    word2idx[word] = i\n",
        "    idx2word[i] = word\n",
        "  return word2idx, idx2word\n",
        "all_texts = (\n",
        "    train_df[\"text\"].astype(str).tolist() +\n",
        "    dev_df[\"text\"].astype(str).tolist() +\n",
        "    test_df[\"text\"].astype(str).tolist()\n",
        ")\n",
        "tokens = set()\n",
        "for text in all_texts:\n",
        "  tokens.update(tokenize(text))\n",
        "word2idx, idx2word = create_vocab(tokens)\n",
        "vocab = word2idx\n",
        "vocab_size = len(vocab)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "6AWKOJpYiSTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1271ea-38a5-40ca-91d1-278b16c2b1d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class c_dataset(Dataset):\n",
        "  def __init__(self, texts, emotions, polarity, empathy, ids=None):\n",
        "    self.texts = texts\n",
        "    self.emotions = emotions\n",
        "    self.polarity = polarity\n",
        "    self.empathy = empathy\n",
        "    self.ids = ids\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "  def __getitem__(self, idx):\n",
        "    tokens = [word2idx.get(word, word2idx[unk_token]) for word in tokenize(str(self.texts[idx]))]\n",
        "    seq = torch.tensor(tokens, dtype=torch.long)\n",
        "    item = {\"seq\": seq}\n",
        "    if self.emotions is not None:\n",
        "      item[\"emotion\"] = torch.tensor(float(self.emotions[idx]), dtype=torch.float)\n",
        "    if self.polarity is not None:\n",
        "      item[\"polarity\"] = torch.tensor(int(self.polarity[idx]), dtype=torch.long)\n",
        "    if self.empathy is not None:\n",
        "      item[\"empathy\"] = torch.tensor(float(self.empathy[idx]), dtype=torch.float)\n",
        "    if self.ids is not None:\n",
        "      item[\"id\"] = self.ids[idx]\n",
        "    return item\n",
        "  def padding_c(batch):\n",
        "    seqs = [b[\"seq\"] for b in batch]\n",
        "    padded = pad_sequence(seqs, batch_first=True, padding_value=word2idx[pad_token])\n",
        "    batch_out = {\"seq\": padded}\n",
        "    for key in [\"emotion\", \"polarity\", \"empathy\", \"id\"]:\n",
        "      if key in batch[0]:\n",
        "        values = [b[key] for b in batch]\n",
        "        if torch.is_tensor(values[0]):\n",
        "          batch_out[key] = torch.stack(values)\n",
        "        else:\n",
        "          batch_out[key] = values\n",
        "    return batch_out"
      ],
      "metadata": {
        "id": "Hyevj3m_NiHe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout, num_classes=3):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "                        dropout=dropout if num_layers > 1 else 0)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc_emotion = nn.Linear(hidden_dim, 1)\n",
        "    self.fc_polarity = nn.Linear(hidden_dim, num_classes)\n",
        "    self.fc_empathy = nn.Linear(hidden_dim, 1)\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    lstm_out, (hidden, _) = self.lstm(embedded)\n",
        "    last_hidden = lstm_out[:, -1, :]\n",
        "    h = self.dropout(last_hidden)\n",
        "    emotion_out = self.fc_emotion(h)\n",
        "    polarity_out = self.fc_polarity(h)\n",
        "    empathy_out = self.fc_empathy(h)\n",
        "    return emotion_out, polarity_out, empathy_out"
      ],
      "metadata": {
        "id": "jULhf5-kTO24"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, device):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  mse = nn.MSELoss()\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "  for batch in loader:\n",
        "    seq = batch[\"seq\"].to(device)\n",
        "    emotion = batch[\"emotion\"].to(device).unsqueeze(1)\n",
        "    polarity = batch[\"polarity\"].to(device)\n",
        "    empathy = batch[\"empathy\"].to(device).unsqueeze(1)\n",
        "    optimizer.zero_grad()\n",
        "    pred_emo, pred_pol, pred_emp = model(seq)\n",
        "    loss = mse(pred_emo, emotion) + ce(pred_pol, polarity) + mse(pred_emp, empathy)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += float(loss.item()) * seq.size(0)\n",
        "  return total_loss / len(loader.dataset)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "  model.eval()\n",
        "  all_true_emotion, all_pred_emotion = [], []\n",
        "  all_true_polarity, all_pred_polarity = [], []\n",
        "  all_true_empathy, all_pred_empathy = [], []\n",
        "  with torch.no_grad():\n",
        "    for batch in loader:\n",
        "      seq = batch[\"seq\"].to(device)\n",
        "      emotion = batch[\"emotion\"].numpy()\n",
        "      polarity = batch[\"polarity\"].numpy()\n",
        "      empathy = batch[\"empathy\"].numpy()\n",
        "      pred_emo, pred_pol, pred_emp = model(seq)\n",
        "      all_true_emotion.extend(pred_emo.cpu().squeeze().numpy())\n",
        "      all_true_polarity.extend(pred_pol.argmax(dim=-1).cpu().numpy())\n",
        "      all_true_empathy.extend(pred_emp.cpu().squeeze().numpy())\n",
        "      all_pred_emotion.extend(emotion)\n",
        "      all_pred_polarity.extend(polarity)\n",
        "      all_pred_empathy.extend(empathy)\n",
        "  mae_emotion = mean_absolute_error(all_pred_emotion, all_true_emotion)\n",
        "  mae_empathy = mean_absolute_error(all_pred_empathy, all_true_empathy)\n",
        "  acc_polarity = accuracy_score(all_pred_polarity, all_true_polarity)\n",
        "  f1_polarity = f1_score(all_pred_polarity, all_true_polarity, average=\"macro\")\n",
        "  # print(\"\\n--- DEV SET PERFORMANCE ---\")\n",
        "  # print(f\"Emotion MAE: {mae_emotion:.4f}\")\n",
        "  # print(f\"Empathy MAE: {mae_empathy:.4f}\")\n",
        "  # print(f\"Polarity Accuracy: {acc_polarity:.4f}\")\n",
        "  # print(f\"Polarity F1 (macro): {f1_polarity:.4f}\")\n",
        "  return mae_emotion, mae_empathy, acc_polarity, f1_polarity, classification_report(all_true_polarity, all_pred_polarity)\n",
        "\n"
      ],
      "metadata": {
        "id": "YybgXW60worP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = c_dataset(train_df[\"text\"], train_df[col_emo], train_df[col_emo_pol], train_df[col_emp])\n",
        "dev_ds = c_dataset(dev_df[\"text\"], dev_df[col_emo], dev_df[col_emo_pol], dev_df[col_emp])\n",
        "test_ds = c_dataset(test_df[\"text\"], None, None, None, ids=test_df[\"id\"])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=c_dataset.padding_c)\n",
        "dev_loader = DataLoader(dev_ds, batch_size=batch_size, shuffle=False, collate_fn=c_dataset.padding_c)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=c_dataset.padding_c)"
      ],
      "metadata": {
        "id": "nQdSdio21p_L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EmotionRNN(vocab_size, embed_dim, hidden_dim, num_layers, dropout, num_classes=3).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, DEVICE)\n",
        "    mae_e, mae_emp, acc, f1, report = evaluate(model, dev_loader, DEVICE)\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | MAE(Emotion)={mae_e:.4f} | MAE(Empathy)={mae_emp:.4f} | Acc(P)={acc:.4f} | F1(P)={f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report (dev, polarity):\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywzZKGG7_sKy",
        "outputId": "7787cba5-4b93-4374-d60c-752c7007ec46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss=2.7902 | MAE(Emotion)=0.6143 | MAE(Empathy)=0.8883 | Acc(P)=0.4580 | F1(P)=0.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | train_loss=2.6801 | MAE(Emotion)=0.5867 | MAE(Empathy)=0.8909 | Acc(P)=0.3761 | F1(P)=0.1822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | train_loss=2.4061 | MAE(Emotion)=0.6472 | MAE(Empathy)=0.8456 | Acc(P)=0.5305 | F1(P)=0.3769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | train_loss=2.1455 | MAE(Emotion)=0.5296 | MAE(Empathy)=0.7952 | Acc(P)=0.5788 | F1(P)=0.4189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | train_loss=1.9396 | MAE(Emotion)=0.5518 | MAE(Empathy)=0.7842 | Acc(P)=0.5788 | F1(P)=0.4197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | train_loss=1.7793 | MAE(Emotion)=0.5491 | MAE(Empathy)=0.7949 | Acc(P)=0.5788 | F1(P)=0.4206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 | train_loss=1.6416 | MAE(Emotion)=0.5232 | MAE(Empathy)=0.7944 | Acc(P)=0.5830 | F1(P)=0.4232\n",
            "Epoch 08 | train_loss=1.5066 | MAE(Emotion)=0.5264 | MAE(Empathy)=0.7926 | Acc(P)=0.5788 | F1(P)=0.4670\n",
            "Epoch 09 | train_loss=1.4254 | MAE(Emotion)=0.5682 | MAE(Empathy)=0.7971 | Acc(P)=0.5977 | F1(P)=0.4960\n",
            "Epoch 10 | train_loss=1.3425 | MAE(Emotion)=0.5457 | MAE(Empathy)=0.7822 | Acc(P)=0.5746 | F1(P)=0.4725\n",
            "\n",
            "Classification report (dev, polarity):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.63      0.18        27\n",
            "           1       0.61      0.61      0.61       440\n",
            "           2       0.73      0.54      0.62       485\n",
            "\n",
            "    accuracy                           0.57       952\n",
            "   macro avg       0.48      0.59      0.47       952\n",
            "weighted avg       0.66      0.57      0.60       952\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test and save CSV\n",
        "model.eval()\n",
        "all_rows = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        seq = batch[\"seq\"].to(DEVICE)\n",
        "        ids = batch[\"id\"]\n",
        "        pred_emo, pred_pol, pred_emp = model(seq)\n",
        "        emo = pred_emo.cpu().squeeze().numpy()\n",
        "        pol = pred_pol.argmax(dim=-1).cpu().numpy()\n",
        "        emp = pred_emp.cpu().squeeze().numpy()\n",
        "        for i in range(len(ids)):\n",
        "            all_rows.append({\n",
        "                \"id\": int(ids[i]),\n",
        "                \"Emotion\": float(emo[i]),\n",
        "                \"EmotionalPolarity\": int(pol[i]),\n",
        "                \"Empathy\": float(emp[i]),\n",
        "            })\n",
        "\n",
        "pred_df = pd.DataFrame(all_rows, columns=[\"id\",\"Emotion\",\"EmotionalPolarity\",\"Empathy\"])\n",
        "out_csv = os.path.join(\"/content/\", \"predictions_ann.csv\")\n",
        "pred_df.to_csv(out_csv, index=False)\n",
        "print(pred_df[\"EmotionalPolarity\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogfsZgg6CqnJ",
        "outputId": "3cd63f1a-a846-44d5-9771-fed769ff84f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmotionalPolarity\n",
            "2    1240\n",
            "1    1017\n",
            "0      59\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}